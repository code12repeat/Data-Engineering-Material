{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b03e4cb7-93a4-4db1-b080-de5204d6106e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: kafka-python in ./.local/lib/python3.9/site-packages (2.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install kafka-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490931e7-040b-4b28-9b86-f73eb4f6ab81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer\n",
    "import json\n",
    " \n",
    "def kafka_consumer_example():\n",
    "    consumer = KafkaConsumer(\n",
    "        'cf_CP',\n",
    "        bootstrap_servers = ['master:9092'],\n",
    "        auto_offset_reset = 'earliest',\n",
    "        enable_auto_commit = True\n",
    "    )\n",
    "    bytes_to_string=lambda byte_data,encoding='utf-8':byte_data.decode(encoding)\n",
    "    print(\"Waiting for messages...\")\n",
    "    for message in consumer:\n",
    "        val=bytes_to_string(message.value)\n",
    "        print(f\"Recieved message length: {len(val)}\")\n",
    "        print(f\"Recieved message : {message.value}\")\n",
    "    consumer.close()\n",
    "if __name__ == \"__main__\":\n",
    "    kafka_consumer_example()\n",
    "    \n",
    "#kafka-console-producer.sh --topic coforge --broker-list master:9092\n",
    "#run above command in terminal to write message\n",
    "\n",
    "#kafka-console-consumer.sh --bootstrap-server master:9092 --topic coforge --from-beginning\n",
    "#above command will show all the messages in terminal\n",
    "\n",
    "#to delete the topic\n",
    "# kafka-topics.sh --bootstrap-server master:9092 --delete --topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ac6597-ade0-41f1-a969-c4a6bec01762",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer\n",
    "import json\n",
    "\n",
    "def kafka_producer_example():\n",
    "    # Initialize Kafka producer\n",
    "    producer = KafkaProducer(\n",
    "        bootstrap_servers=['master:9092'],  # Replace with your Kafka broker address\n",
    "        value_serializer=lambda v: json.dumps(v).encode('utf-8')\n",
    "    )\n",
    "    \n",
    "    # Send a message\n",
    "    for i in range(10):\n",
    "        topic_name = 'sub_1'\n",
    "        message = {'key': i}  # Replace with your actual message\n",
    "        producer.send(topic_name, message)\n",
    "        producer.flush()  # Ensure all messages are sent before exiting\n",
    "\n",
    "        print(f\"Message sent to {topic_name}: {message}\")\n",
    "    producer.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    kafka_producer_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cad27da-2f88-4c4f-aa77-ae564eb909d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import expr\n",
    "# Initialize SparkSession with Kafka dependencies\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"KafkaStructuredStreamingExample\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.2\") \\\n",
    "    .config(\"spark.yarn.jars\", \"hdfs:///opt/spark/*.jar\") \\\n",
    "    .getOrCreate()\n",
    "# Kafka configuration details\n",
    "kafka_bootstrap_servers = \"master:9092\"  # Replace with your Kafka broker address\n",
    "kafka_topic = \"gfg\"  # Replace with your Kafka topic\n",
    "# Read data from Kafka\n",
    "df = spark.readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", kafka_bootstrap_servers) \\\n",
    "    .option(\"subscribe\", kafka_topic) \\\n",
    "    .option(\"startingOffsets\",\"earliest\") \\\n",
    "    .load()\n",
    "# Extract the 'value' column from the Kafka message and cast it to a string\n",
    "kafka_df = df.selectExpr(\"CAST(value AS STRING)\")\n",
    "# Write the output to the console (this works in notebook output)\n",
    "query = kafka_df.writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"console\") \\\n",
    "    .start()\n",
    "# Await termination (in a notebook, you might want to limit this or use a specific timeout)\n",
    "# In a Jupyter notebook, we use a short timeout to avoid blocking the notebook for too long\n",
    "query.awaitTermination(60)\n",
    "has context menu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
