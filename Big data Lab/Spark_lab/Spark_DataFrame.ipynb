{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8489fb-0c24-4b13-a636-66122805a980",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. **Creating a DataFrame**\n",
    "To create a DataFrame in Spark, you typically use the `SparkSession` object. Below is an example using a list of tuples and a schema.\n",
    "\n",
    "**Q: How do you create a DataFrame from a list of tuples in Spark?**\n",
    "\n",
    "```python\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder.appName(\"DataFrameExample\").getOrCreate()\n",
    "\n",
    "# Sample data\n",
    "data = [(\"Alice\", 34), (\"Bob\", 45), (\"Cathy\", 29)]\n",
    "\n",
    "# Define schema\n",
    "schema = StructType([\n",
    "    StructField(\"Name\", StringType(), True),\n",
    "    StructField(\"Age\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, schema)\n",
    "```\n",
    "\n",
    "### 2. **Filtering Data**\n",
    "\n",
    "**Q: How do you filter rows in a DataFrame where the age is greater than 30?**\n",
    "\n",
    "```python\n",
    "# Filter rows where Age > 30\n",
    "filtered_df = df.filter(df.Age > 30)\n",
    "```\n",
    "\n",
    "### 3. **Selecting Specific Columns**\n",
    "\n",
    "**Q: How do you select specific columns, such as \"Name\" only, from a DataFrame?**\n",
    "\n",
    "```python\n",
    "# Select the 'Name' column\n",
    "name_df = df.select(\"Name\")\n",
    "```\n",
    "\n",
    "### 4. **Adding a New Column**\n",
    "\n",
    "**Q: How do you add a new column to a DataFrame that calculates the age in months?**\n",
    "\n",
    "```python\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Add a new column 'AgeInMonths'\n",
    "df_with_new_column = df.withColumn(\"AgeInMonths\", col(\"Age\") * 12)\n",
    "```\n",
    "\n",
    "### 5. **Renaming a Column**\n",
    "\n",
    "**Q: How do you rename the column \"Age\" to \"Years\"?**\n",
    "\n",
    "```python\n",
    "# Rename the 'Age' column to 'Years'\n",
    "df_renamed = df.withColumnRenamed(\"Age\", \"Years\")\n",
    "```\n",
    "\n",
    "### 6. **Grouping and Aggregation**\n",
    "\n",
    "**Q: How do you group by a column and perform an aggregation, such as counting the number of occurrences for each \"Age\"?**\n",
    "\n",
    "```python\n",
    "# Group by 'Age' and count the occurrences\n",
    "grouped_df = df.groupBy(\"Age\").count()\n",
    "```\n",
    "\n",
    "### 7. **Joining DataFrames**\n",
    "\n",
    "**Q: How do you perform an inner join on two DataFrames based on a common column, such as \"Name\"?**\n",
    "\n",
    "```python\n",
    "# Sample data for another DataFrame\n",
    "data2 = [(\"Alice\", \"F\"), (\"Bob\", \"M\"), (\"David\", \"M\")]\n",
    "\n",
    "# Create another DataFrame\n",
    "df2 = spark.createDataFrame(data2, [\"Name\", \"Gender\"])\n",
    "\n",
    "# Perform an inner join on 'Name' column\n",
    "joined_df = df.join(df2, on=\"Name\", how=\"inner\")\n",
    "```\n",
    "\n",
    "### 8. **Sorting Data**\n",
    "\n",
    "**Q: How do you sort a DataFrame by the \"Age\" column in descending order?**\n",
    "\n",
    "```python\n",
    "# Sort by 'Age' in descending order\n",
    "sorted_df = df.orderBy(df.Age.desc())\n",
    "```\n",
    "\n",
    "### 9. **Dropping Duplicates**\n",
    "\n",
    "**Q: How do you remove duplicate rows based on a specific column, such as \"Name\"?**\n",
    "\n",
    "```python\n",
    "# Drop duplicates based on 'Name'\n",
    "distinct_df = df.dropDuplicates([\"Name\"])\n",
    "```\n",
    "\n",
    "### 10. **Handling Missing Data**\n",
    "\n",
    "**Q: How do you fill missing values in a DataFrame's column with a default value, like filling missing \"Age\" values with 0?**\n",
    "\n",
    "```python\n",
    "# Fill missing values in 'Age' column with 0\n",
    "filled_df = df.fillna({\"Age\": 0})\n",
    "```\n",
    "\n",
    "### 11. **Union of DataFrames**\n",
    "\n",
    "**Q: How do you perform a union of two DataFrames with the same schema?**\n",
    "\n",
    "```python\n",
    "# Union two DataFrames\n",
    "union_df = df.union(df2)\n",
    "```\n",
    "\n",
    "### 12. **Collecting Data**\n",
    "\n",
    "**Q: How do you collect the DataFrame's content as a list of rows?**\n",
    "\n",
    "```python\n",
    "# Collect DataFrame content\n",
    "collected_data = df.collect()\n",
    "```\n",
    "\n",
    "### 13. **Writing Data to a File**\n",
    "\n",
    "**Q: How do you write a DataFrame to a CSV file?**\n",
    "\n",
    "```python\n",
    "# Write DataFrame to a CSV file\n",
    "df.write.csv(\"output.csv\")\n",
    "```\n",
    "\n",
    "### 14. **Reading Data from a File**\n",
    "\n",
    "**Q: How do you read a CSV file into a DataFrame?**\n",
    "\n",
    "```python\n",
    "# Read a CSV file into a DataFrame\n",
    "df_from_csv = spark.read.csv(\"input.csv\", header=True, inferSchema=True)\n",
    "```\n",
    "\n",
    "These examples cover a wide range of operations you can perform with Spark DataFrames. Adjust and use these operations based on your specific data processing needs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
