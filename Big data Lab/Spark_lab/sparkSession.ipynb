{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b76d041-1a6a-4553-9f52-b6fddaaff5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SparkSession is for dataframe\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62fbde50-82e6-4df9-8567-3f39f73e885d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-28 16:08:37,704 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "2024-08-28 16:08:39,000 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "2024-08-28 16:08:40,177 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>96931</td>\n",
       "      <td>other or not specified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>134</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>66212</td>\n",
       "      <td>other or not specified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>45237</td>\n",
       "      <td>other or not specified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>179</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>2135</td>\n",
       "      <td>other or not specified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>235</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>98153</td>\n",
       "      <td>other or not specified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id gender  age zipcode              occupation\n",
       "0       53      M   25   96931  other or not specified\n",
       "1      134      M   25   66212  other or not specified\n",
       "2      173      M   25   45237  other or not specified\n",
       "3      179      M   25    2135  other or not specified\n",
       "4      235      M   25   98153  other or not specified"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize the SparkSession\n",
    "spark=SparkSession.builder.appName('CSV to DataFrame').getOrCreate()\n",
    "# path to csv file\n",
    "csv_file_path='users.csv'\n",
    "#read the CSV file into dataframe\n",
    "# df=spark.read.csv(csv_file_path,header=True,inferSchema=True)\n",
    "dt=pd.read_csv('users.csv')\n",
    "#show the first few rows of the dataframe\n",
    "dt.head()\n",
    "#display the schema of the dataframe\n",
    "# df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc9b7cf-f325-40fa-a3f6-70411091e958",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-28 16:09:32,906 WARN cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "2024-08-28 16:09:47,905 WARN cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "2024-08-28 16:10:02,906 WARN cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "2024-08-28 16:10:17,905 WARN cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "[Stage 0:>                                                          (0 + 0) / 1]\r"
     ]
    }
   ],
   "source": [
    "#convert pandas DataFrame into spark DataFrame\n",
    "spark_df=spark.createDataFrame(dt)\n",
    "\n",
    "#show the first few rows of the dataframe\n",
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54026a0b-68ea-4153-9773-f2f4565a603e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- zipcode: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#display the schema of the dataframe\n",
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6485f86-083b-4b34-b8d5-1008d61133fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---+-------+----------------------+\n",
      "|user_id|gender|age|zipcode|occupation            |\n",
      "+-------+------+---+-------+----------------------+\n",
      "|53     |M     |25 |96931  |other or not specified|\n",
      "|134    |M     |25 |66212  |other or not specified|\n",
      "|173    |M     |25 |45237  |other or not specified|\n",
      "|179    |M     |25 |2135   |other or not specified|\n",
      "|235    |M     |25 |98153  |other or not specified|\n",
      "|275    |M     |25 |48162  |other or not specified|\n",
      "|283    |M     |25 |10003  |other or not specified|\n",
      "|304    |M     |25 |55414  |other or not specified|\n",
      "|368    |M     |25 |90293  |other or not specified|\n",
      "|386    |M     |25 |55408  |other or not specified|\n",
      "|414    |M     |25 |55317  |other or not specified|\n",
      "|513    |M     |25 |55119  |other or not specified|\n",
      "|591    |M     |25 |76201  |other or not specified|\n",
      "|607    |M     |25 |43614  |other or not specified|\n",
      "|618    |M     |25 |74105  |other or not specified|\n",
      "|622    |M     |25 |92612  |other or not specified|\n",
      "|678    |M     |25 |34952  |other or not specified|\n",
      "|708    |M     |25 |37042  |other or not specified|\n",
      "|712    |M     |25 |95136  |other or not specified|\n",
      "|730    |M     |25 |10580  |other or not specified|\n",
      "+-------+------+---+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.filter(spark_df.gender=='M').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a0762a-4362-4e01-9632-1065d43a1c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
