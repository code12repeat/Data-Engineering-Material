{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdbdbb40-0a6d-4578-a970-0a35ef8e41f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the SparkSession from pyspark\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c5f7667-4a86-4ef7-9bf2-24f82e877e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 11:20:15,310 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "2024-09-07 11:20:16,128 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "2024-09-07 11:20:16,128 WARN util.Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "2024-09-07 11:20:16,128 WARN util.Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "2024-09-07 11:20:16,773 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "#start the spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SalesDataStreaming\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e54e2972-edaf-41a1-acfa-3b9563bcd6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.engine import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "host='localhost' #Since hive is running localy\n",
    "port=10000 # Default port for HiveServer2\n",
    "username='maneelcha49dgre'\n",
    "database='fireBase'\n",
    "\n",
    "connection_string=f'hive://{username}@{host}:{port}/{database}'\n",
    "\n",
    "engine=create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a155bf5-eacf-4d9e-8b65-66a649530925",
   "metadata": {},
   "source": [
    "### 1. Schema Definition and Data Loading (5 Marks):\n",
    "##### ● Task: Set up the schema for each dataset using the provided structure.Load the datasets from their respective locations using file-structured streaming.\n",
    "##### ● Expected Result: Accurate schema definition and successful data loadinginto data frames without errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14253b69-74fa-4839-900c-a569d7634ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hadoop 3.3.0\n",
      "Source code repository https://gitbox.apache.org/repos/asf/hadoop.git -r aa96f1871bfd858f9bac59cf2a81ec470da649af\n",
      "Compiled by brahma on 2020-07-06T18:44Z\n",
      "Compiled with protoc 3.7.1\n",
      "From source with checksum 5dc29b802d6ccd77b262ef9d04d19c4\n",
      "This command was run using /opt/hadoop/share/hadoop/common/hadoop-common-3.3.0.jar\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.environ['HADOOP_HOME'] = '/opt/hadoop' \n",
    "os.environ['PATH'] += os.pathsep + os.path.join(os.environ['HADOOP_HOME'], 'bin') \n",
    "!hadoop version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a3d65ac-fe9d-4059-817e-da36b2476e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#put all csv into list\n",
    "file_list = ['myfiles/transaction_data.csv','myfiles/merchant_data.csv', 'myfiles/account_data.csv', 'myfiles/customer_data.csv', 'myfiles/branch_data.csv.csv']\n",
    "loading csv files from local to hdfs\n",
    "#load csv file from local to hdfs\n",
    "for file in file_list:\n",
    "    os.system(f'hdfs dfs -put {file} /user/maneelcha49dgre/review_file1/' )\n",
    "print(\"successfully loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d689e844-2160-497c-88d7-20660da02ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "schema = [\n",
    "    \"\"\"create table if not exists transaction_data(\n",
    "    Transaction_ID string,\n",
    "    Account_ID string,\n",
    "    merchant_id string,\n",
    "    Transaction_Date date,\n",
    "    Processing_Date date,\n",
    "    Amount double\n",
    "    )\n",
    "    ROW FORMAT DELIMITED\n",
    "    FIELDS TERMINATED BY ','\n",
    "    STORED AS TEXTFILE\n",
    "    TBLPROPERTIES (\"skip.header.line.count\" = \"1\")\n",
    "    \"\"\",\n",
    "    \"\"\"create table if not exists merchant_data(\n",
    "    Merchant_ID string,\n",
    "    Merchant_Name string ,\n",
    "    Merchant_Category string, \n",
    "    Country string\n",
    "    )\n",
    "    ROW FORMAT DELIMITED\n",
    "    FIELDS TERMINATED BY ','\n",
    "    STORED AS TEXTFILE\n",
    "    TBLPROPERTIES (\"skip.header.line.count\" = \"1\")\n",
    "    \"\"\",\n",
    "    \"\"\"create table if not exists account_data(\n",
    "    Account_ID string,\n",
    "    Customer_ID string,\n",
    "    Branch_ID string,\n",
    "    Account_Type string,\n",
    "    Balance double\n",
    "    )\n",
    "    ROW FORMAT DELIMITED\n",
    "    FIELDS TERMINATED BY ','\n",
    "    STORED AS TEXTFILE\n",
    "    TBLPROPERTIES (\"skip.header.line.count\" = \"1\")\n",
    "    \"\"\",\n",
    "    \"\"\" create table if not exists customer_data(\n",
    "    Customer_ID string,\n",
    "    Customer_Name string,\n",
    "    Customer_Type string,\n",
    "    Customer_Country string\n",
    "    )\n",
    "    ROW FORMAT DELIMITED\n",
    "    FIELDS TERMINATED BY ','\n",
    "    STORED AS TEXTFILE\n",
    "    TBLPROPERTIES (\"skip.header.line.count\" = \"1\")\n",
    "    \"\"\",\n",
    "    \"\"\"create table if not exists branch_data(\n",
    "    Branch_ID string,\n",
    "    Branch_Name string,\n",
    "    Location string,\n",
    "    Manager string\n",
    "    )\n",
    "    ROW FORMAT DELIMITED\n",
    "    FIELDS TERMINATED BY ','\n",
    "    STORED AS TEXTFILE\n",
    "    TBLPROPERTIES (\"skip.header.line.count\" = \"1\")\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "for tables in schema:\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf730f86-dd6a-4783-ab59-a0204547548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of all the tables created\n",
    "with engine.connect() as connection:\n",
    "    res=connection.execute(\"show tables\")\n",
    "for x in res:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bbd094c-6232-4b44-a4ac-33afd1d2db44",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_list=[\"transaction_data\",\"merchant_data\",\"account_data\",\"customer_data\",\"branch_data\"]\n",
    "dataset_list=[\"transaction_data.csv\",\"merchant_data.csv\",\"account_data.csv\",\"customer_data.csv\",\"branch_data.csv\"]\n",
    "\n",
    "for i in range(len(table_list)):\n",
    "    load_file=f\"load data inpath '/user/maneelcha49dgre/review_file1/{dataset_list[i]}' into table {table_list[i]}\"\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(load_file)            \n",
    "print('Successfully loaded')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c982c363-c05c-4883-a103-0fe0db7fd3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created dataframe\n"
     ]
    }
   ],
   "source": [
    "#store all the tables record into pandas dataframe\n",
    "trans_df=pd.read_sql(\"select * from transaction_data\",engine)\n",
    "merch_df=pd.read_sql(\"select * from merchant_data\",engine)\n",
    "acc_df=pd.read_sql(\"select * from account_data\",engine)\n",
    "cust_df=pd.read_sql(\"select * from customer_data\",engine)\n",
    "branch_df=pd.read_sql(\"select * from branch_data\",engine)\n",
    "\n",
    "print(\"Successfully created dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f2de1ab-23b8-4ce7-8590-08c53288b712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created spark dataframe\n"
     ]
    }
   ],
   "source": [
    "spark_trans_df=spark.createDataFrame(trans_df)\n",
    "spark_merch_df=spark.createDataFrame(merch_df)\n",
    "spark_acc_df=spark.createDataFrame(acc_df)\n",
    "spark_cust_df=spark.createDataFrame(cust_df)\n",
    "spark_branch_df=spark.createDataFrame(branch_df)\n",
    "\n",
    "print(\"Successfully created spark dataframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec3df57-03d9-4807-93bd-a00045601d1b",
   "metadata": {},
   "source": [
    "### 2. DataFrame Merging (5 Marks):\n",
    "● Task: Join all the data frames (account_data, transaction_data,customer_data, merchant_data, branch_data) into a single data frame called Full_DataFrame. Ensure the resulting data frame does not contain duplicate columns.\n",
    "\n",
    "● Expected Result: Correct and efficient merging, with no duplicate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e7b2e91-8d3f-497f-94d4-6819b3147b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------------+----------------+---------------+------+---------+-----------+------------+-------+-------------+-------------+----------------+-----------+--------+---------+-------------+-----------------+-------+\n",
      "|merchant_id|account_id|transaction_id|transaction_date|processing_date|amount|branch_id|customer_id|account_type|balance|customer_name|customer_type|customer_country|branch_name|location|  manager|merchant_name|merchant_category|country|\n",
      "+-----------+----------+--------------+----------------+---------------+------+---------+-----------+------------+-------+-------------+-------------+----------------+-----------+--------+---------+-------------+-----------------+-------+\n",
      "|     MER006|    ACC010|        TXN006|      2024-08-05|     2024-07-29|252.03|   BID003|    CUST010|    Checking|3340.17|  Customer_10|   Individual|          Canada|   Branch_3| Toronto|Manager_3|   Merchant_6|    Entertainment|    USA|\n",
      "|     MER015|    ACC012|        TXN015|      2024-06-04|     2024-08-16|481.38|   BID003|    CUST012|     Savings|4079.33|  Customer_12|     Business|         Germany|   Branch_3| Toronto|Manager_3|  Merchant_15|         Clothing| Canada|\n",
      "|     MER004|    ACC014|        TXN004|      2024-08-10|     2024-06-09|132.45|   BID005|    CUST014|     Savings|3996.16|  Customer_14|   Individual|             USA|   Branch_5|  Berlin|Manager_5|   Merchant_4|         Clothing| Canada|\n",
      "|     MER003|    ACC014|        TXN003|      2024-08-29|     2024-06-11|168.53|   BID005|    CUST014|     Savings|3996.16|  Customer_14|   Individual|             USA|   Branch_5|  Berlin|Manager_5|   Merchant_3|        Groceries| Canada|\n",
      "|       null|    ACC013|          null|            null|           null|  null|   BID003|    CUST013|     Savings| 1203.2|  Customer_13|   Individual|             USA|   Branch_3| Toronto|Manager_3|         null|             null|   null|\n",
      "|       null|    ACC009|          null|            null|           null|  null|   BID005|    CUST009|    Checking| 3842.5|   Customer_9|   Individual|          Canada|   Branch_5|  Berlin|Manager_5|         null|             null|   null|\n",
      "|       null|    ACC001|          null|            null|           null|  null|   BID001|    CUST001|    Checking|6028.87|   Customer_1|     Business|              UK|   Branch_1|New York|Manager_1|         null|             null|   null|\n",
      "|       null|    ACC008|          null|            null|           null|  null|   BID005|    CUST008|     Savings| 5803.6|   Customer_8|     Business|             USA|   Branch_5|  Berlin|Manager_5|         null|             null|   null|\n",
      "|       null|    ACC007|          null|            null|           null|  null|   BID001|    CUST007|     Savings|9405.52|   Customer_7|   Individual|              UK|   Branch_1|New York|Manager_1|         null|             null|   null|\n",
      "|       null|    ACC002|          null|            null|           null|  null|   BID004|    CUST002|    Checking|5696.32|   Customer_2|     Business|          Canada|   Branch_4|New York|Manager_4|         null|             null|   null|\n",
      "|       null|    ACC011|          null|            null|           null|  null|   BID002|    CUST011|    Checking|2663.98|  Customer_11|     Business|         Germany|   Branch_2|  Berlin|Manager_2|         null|             null|   null|\n",
      "|     MER013|    ACC003|        TXN013|      2024-06-18|     2024-06-18|191.21|   BID001|    CUST003|    Checking|6646.05|   Customer_3|     Business|             USA|   Branch_1|New York|Manager_1|  Merchant_13|         Clothing|Germany|\n",
      "|     MER002|    ACC004|        TXN002|      2024-09-03|     2024-07-12|499.71|   BID004|    CUST004|     Savings|2518.68|   Customer_4|   Individual|              UK|   Branch_4|New York|Manager_4|   Merchant_2|      Electronics|    USA|\n",
      "|     MER010|    ACC015|        TXN010|      2024-07-01|     2024-07-13|270.77|   BID003|    CUST015|    Checking|9530.01|  Customer_15|     Business|             USA|   Branch_3| Toronto|Manager_3|  Merchant_10|    Entertainment| Canada|\n",
      "|     MER011|    ACC010|        TXN011|      2024-07-25|     2024-08-20|346.12|   BID003|    CUST010|    Checking|3340.17|  Customer_10|   Individual|          Canada|   Branch_3| Toronto|Manager_3|  Merchant_11|      Electronics|     UK|\n",
      "|     MER008|    ACC006|        TXN008|      2024-07-04|     2024-07-21|455.89|   BID002|    CUST006|     Savings|9322.52|   Customer_6|   Individual|          Canada|   Branch_2|  Berlin|Manager_2|   Merchant_8|        Groceries|    USA|\n",
      "|     MER014|    ACC005|        TXN014|      2024-07-25|     2024-08-05|170.04|   BID002|    CUST005|     Savings|2626.92|   Customer_5|     Business|         Germany|   Branch_2|  Berlin|Manager_2|  Merchant_14|    Entertainment|Germany|\n",
      "|     MER001|    ACC012|        TXN001|      2024-07-02|     2024-07-20|354.28|   BID003|    CUST012|     Savings|4079.33|  Customer_12|     Business|         Germany|   Branch_3| Toronto|Manager_3|   Merchant_1|        Groceries|Germany|\n",
      "|     MER005|    ACC006|        TXN005|      2024-06-13|     2024-08-16|374.18|   BID002|    CUST006|     Savings|9322.52|   Customer_6|   Individual|          Canada|   Branch_2|  Berlin|Manager_2|   Merchant_5|    Entertainment| Canada|\n",
      "|     MER007|    ACC014|        TXN007|      2024-06-22|     2024-09-02|288.11|   BID005|    CUST014|     Savings|3996.16|  Customer_14|   Individual|             USA|   Branch_5|  Berlin|Manager_5|   Merchant_7|      Electronics|Germany|\n",
      "+-----------+----------+--------------+----------------+---------------+------+---------+-----------+------------+-------+-------------+-------------+----------------+-----------+--------+---------+-------------+-----------------+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join all the dataframes into one\n",
    "merged_data=spark_acc_df.join(spark_cust_df,on=['Customer_ID'],how='left')\n",
    "merged_data=merged_data.join(spark_branch_df,on=['Branch_Id'],how='left')\n",
    "merged_data=spark_trans_df.join(merged_data,on=['Account_ID'],how='right')\n",
    "merged_data=merged_data.join(spark_merch_df,on=['Merchant_ID'],how='left')\n",
    "print(merged_data.show())\n",
    "merged_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fac261-83b2-497a-b247-105168e12083",
   "metadata": {},
   "source": [
    "### 3. Calculating Transaction Anomalies (5 Marks):\n",
    "● Task: Identify transactions where the processing time exceeds 7 days and flag them as anomalies by creating a new column Anomaly.\n",
    "\n",
    "● Expected Result: A new column Anomaly where transactions with processing time > 7 days are marked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a298b6f3-27b2-434c-8fc4-cf345622631d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>account_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>processing_date</th>\n",
       "      <th>amount</th>\n",
       "      <th>processing_time</th>\n",
       "      <th>anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TXN001</td>\n",
       "      <td>ACC012</td>\n",
       "      <td>MER001</td>\n",
       "      <td>2024-07-02</td>\n",
       "      <td>2024-07-20</td>\n",
       "      <td>354.28</td>\n",
       "      <td>18</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TXN002</td>\n",
       "      <td>ACC004</td>\n",
       "      <td>MER002</td>\n",
       "      <td>2024-09-03</td>\n",
       "      <td>2024-07-12</td>\n",
       "      <td>499.71</td>\n",
       "      <td>-53</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TXN003</td>\n",
       "      <td>ACC014</td>\n",
       "      <td>MER003</td>\n",
       "      <td>2024-08-29</td>\n",
       "      <td>2024-06-11</td>\n",
       "      <td>168.53</td>\n",
       "      <td>-79</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TXN004</td>\n",
       "      <td>ACC014</td>\n",
       "      <td>MER004</td>\n",
       "      <td>2024-08-10</td>\n",
       "      <td>2024-06-09</td>\n",
       "      <td>132.45</td>\n",
       "      <td>-62</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TXN005</td>\n",
       "      <td>ACC006</td>\n",
       "      <td>MER005</td>\n",
       "      <td>2024-06-13</td>\n",
       "      <td>2024-08-16</td>\n",
       "      <td>374.18</td>\n",
       "      <td>64</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TXN006</td>\n",
       "      <td>ACC010</td>\n",
       "      <td>MER006</td>\n",
       "      <td>2024-08-05</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>252.03</td>\n",
       "      <td>-7</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TXN007</td>\n",
       "      <td>ACC014</td>\n",
       "      <td>MER007</td>\n",
       "      <td>2024-06-22</td>\n",
       "      <td>2024-09-02</td>\n",
       "      <td>288.11</td>\n",
       "      <td>72</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TXN008</td>\n",
       "      <td>ACC006</td>\n",
       "      <td>MER008</td>\n",
       "      <td>2024-07-04</td>\n",
       "      <td>2024-07-21</td>\n",
       "      <td>455.89</td>\n",
       "      <td>17</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TXN009</td>\n",
       "      <td>ACC005</td>\n",
       "      <td>MER009</td>\n",
       "      <td>2024-08-10</td>\n",
       "      <td>2024-08-25</td>\n",
       "      <td>375.36</td>\n",
       "      <td>15</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TXN010</td>\n",
       "      <td>ACC015</td>\n",
       "      <td>MER010</td>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>2024-07-13</td>\n",
       "      <td>270.77</td>\n",
       "      <td>12</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TXN011</td>\n",
       "      <td>ACC010</td>\n",
       "      <td>MER011</td>\n",
       "      <td>2024-07-25</td>\n",
       "      <td>2024-08-20</td>\n",
       "      <td>346.12</td>\n",
       "      <td>26</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TXN012</td>\n",
       "      <td>ACC005</td>\n",
       "      <td>MER012</td>\n",
       "      <td>2024-06-24</td>\n",
       "      <td>2024-06-30</td>\n",
       "      <td>465.39</td>\n",
       "      <td>6</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TXN013</td>\n",
       "      <td>ACC003</td>\n",
       "      <td>MER013</td>\n",
       "      <td>2024-06-18</td>\n",
       "      <td>2024-06-18</td>\n",
       "      <td>191.21</td>\n",
       "      <td>0</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TXN014</td>\n",
       "      <td>ACC005</td>\n",
       "      <td>MER014</td>\n",
       "      <td>2024-07-25</td>\n",
       "      <td>2024-08-05</td>\n",
       "      <td>170.04</td>\n",
       "      <td>11</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TXN015</td>\n",
       "      <td>ACC012</td>\n",
       "      <td>MER015</td>\n",
       "      <td>2024-06-04</td>\n",
       "      <td>2024-08-16</td>\n",
       "      <td>481.38</td>\n",
       "      <td>73</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   transaction_id account_id merchant_id transaction_date processing_date  \\\n",
       "0          TXN001     ACC012      MER001       2024-07-02      2024-07-20   \n",
       "1          TXN002     ACC004      MER002       2024-09-03      2024-07-12   \n",
       "2          TXN003     ACC014      MER003       2024-08-29      2024-06-11   \n",
       "3          TXN004     ACC014      MER004       2024-08-10      2024-06-09   \n",
       "4          TXN005     ACC006      MER005       2024-06-13      2024-08-16   \n",
       "5          TXN006     ACC010      MER006       2024-08-05      2024-07-29   \n",
       "6          TXN007     ACC014      MER007       2024-06-22      2024-09-02   \n",
       "7          TXN008     ACC006      MER008       2024-07-04      2024-07-21   \n",
       "8          TXN009     ACC005      MER009       2024-08-10      2024-08-25   \n",
       "9          TXN010     ACC015      MER010       2024-07-01      2024-07-13   \n",
       "10         TXN011     ACC010      MER011       2024-07-25      2024-08-20   \n",
       "11         TXN012     ACC005      MER012       2024-06-24      2024-06-30   \n",
       "12         TXN013     ACC003      MER013       2024-06-18      2024-06-18   \n",
       "13         TXN014     ACC005      MER014       2024-07-25      2024-08-05   \n",
       "14         TXN015     ACC012      MER015       2024-06-04      2024-08-16   \n",
       "\n",
       "    amount  processing_time anomaly  \n",
       "0   354.28               18     YES  \n",
       "1   499.71              -53      NO  \n",
       "2   168.53              -79      NO  \n",
       "3   132.45              -62      NO  \n",
       "4   374.18               64     YES  \n",
       "5   252.03               -7      NO  \n",
       "6   288.11               72     YES  \n",
       "7   455.89               17     YES  \n",
       "8   375.36               15     YES  \n",
       "9   270.77               12     YES  \n",
       "10  346.12               26     YES  \n",
       "11  465.39                6      NO  \n",
       "12  191.21                0      NO  \n",
       "13  170.04               11     YES  \n",
       "14  481.38               73     YES  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"\"\" select * ,datediff(processing_date,transaction_date) as processing_time,\n",
    "case\n",
    "  when datediff(processing_date,transaction_date)>7 then 'YES'\n",
    "  else 'NO'\n",
    "end as Anomaly\n",
    "from transaction_data\"\"\"\n",
    "pd.read_sql(query,engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a309558-6ecb-4930-a02b-a744eba973e5",
   "metadata": {},
   "source": [
    "### 4. Branch-Level Monthly Profit Trends (5 Marks):\n",
    "● Task: For each branch, calculate the monthly total transaction amount and identify the month with the highest profit for each branch.\n",
    "\n",
    "● Expected Result: Correctly calculated total monthly profits per branch and identified the month with the highest profit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27a57774-bbbe-4245-b20c-25f41d5bea50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+-----+--------------------+\n",
      "|branch_id|Year|Month|Monthly_Trans_Amount|\n",
      "+---------+----+-----+--------------------+\n",
      "|   BID005|2024|    8|              300.98|\n",
      "|   BID002|2024|    6|   839.5699999999999|\n",
      "|   BID004|2024|    9|              499.71|\n",
      "|   BID003|2024|    7|              971.17|\n",
      "|   BID001|2024|    6|              191.21|\n",
      "+---------+----+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import required libraries\n",
    "from pyspark.sql.functions import col, year, month, sum, max, row_number\n",
    "from pyspark.sql import Window\n",
    "#copy original datset into temp variable\n",
    "result=merged_data\n",
    "\n",
    "result = result.withColumn(\"Year\", year(col(\"transaction_date\")))\n",
    "\n",
    "result = result.withColumn(\"Month\", month(col(\"transaction_date\")))\n",
    "\n",
    "#monthly transaction\n",
    "monthly_trans_df = result.groupBy(\"branch_id\", \"Year\", \"Month\") \\\n",
    "    .agg(sum(\"amount\").alias(\"Monthly_Trans_Amount\"))\n",
    "\n",
    "#Use window function\n",
    "window = Window.partitionBy(\"branch_id\").orderBy(col(\"Monthly_Trans_Amount\").desc())\n",
    "\n",
    "highest_prof_df = monthly_trans_df.withColumn(\"Rank\", row_number().over(window)) \\\n",
    "    .filter(col(\"Rank\") == 1) \\\n",
    "    .drop(\"Rank\")\n",
    "highest_prof_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd30361-e39d-4db8-a34f-998039d6efe9",
   "metadata": {},
   "source": [
    "### 5. Transaction Processing Time Calculation (5 Marks):\n",
    "● Task: Create a new column ProcessingTime that calculates the difference in days between Transaction_Date and Processing_Date. Validate the calculation by showing sample data.\n",
    "\n",
    "● Expected Result: Correct calculation of processing time with sample data validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd6b68eb-7558-4a32-8eb6-154c47669735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>account_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>processing_date</th>\n",
       "      <th>amount</th>\n",
       "      <th>processing_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TXN001</td>\n",
       "      <td>ACC012</td>\n",
       "      <td>MER001</td>\n",
       "      <td>2024-07-02</td>\n",
       "      <td>2024-07-20</td>\n",
       "      <td>354.28</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TXN002</td>\n",
       "      <td>ACC004</td>\n",
       "      <td>MER002</td>\n",
       "      <td>2024-09-03</td>\n",
       "      <td>2024-07-12</td>\n",
       "      <td>499.71</td>\n",
       "      <td>-53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TXN003</td>\n",
       "      <td>ACC014</td>\n",
       "      <td>MER003</td>\n",
       "      <td>2024-08-29</td>\n",
       "      <td>2024-06-11</td>\n",
       "      <td>168.53</td>\n",
       "      <td>-79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TXN004</td>\n",
       "      <td>ACC014</td>\n",
       "      <td>MER004</td>\n",
       "      <td>2024-08-10</td>\n",
       "      <td>2024-06-09</td>\n",
       "      <td>132.45</td>\n",
       "      <td>-62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TXN005</td>\n",
       "      <td>ACC006</td>\n",
       "      <td>MER005</td>\n",
       "      <td>2024-06-13</td>\n",
       "      <td>2024-08-16</td>\n",
       "      <td>374.18</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TXN006</td>\n",
       "      <td>ACC010</td>\n",
       "      <td>MER006</td>\n",
       "      <td>2024-08-05</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>252.03</td>\n",
       "      <td>-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TXN007</td>\n",
       "      <td>ACC014</td>\n",
       "      <td>MER007</td>\n",
       "      <td>2024-06-22</td>\n",
       "      <td>2024-09-02</td>\n",
       "      <td>288.11</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TXN008</td>\n",
       "      <td>ACC006</td>\n",
       "      <td>MER008</td>\n",
       "      <td>2024-07-04</td>\n",
       "      <td>2024-07-21</td>\n",
       "      <td>455.89</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TXN009</td>\n",
       "      <td>ACC005</td>\n",
       "      <td>MER009</td>\n",
       "      <td>2024-08-10</td>\n",
       "      <td>2024-08-25</td>\n",
       "      <td>375.36</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TXN010</td>\n",
       "      <td>ACC015</td>\n",
       "      <td>MER010</td>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>2024-07-13</td>\n",
       "      <td>270.77</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TXN011</td>\n",
       "      <td>ACC010</td>\n",
       "      <td>MER011</td>\n",
       "      <td>2024-07-25</td>\n",
       "      <td>2024-08-20</td>\n",
       "      <td>346.12</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TXN012</td>\n",
       "      <td>ACC005</td>\n",
       "      <td>MER012</td>\n",
       "      <td>2024-06-24</td>\n",
       "      <td>2024-06-30</td>\n",
       "      <td>465.39</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TXN013</td>\n",
       "      <td>ACC003</td>\n",
       "      <td>MER013</td>\n",
       "      <td>2024-06-18</td>\n",
       "      <td>2024-06-18</td>\n",
       "      <td>191.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TXN014</td>\n",
       "      <td>ACC005</td>\n",
       "      <td>MER014</td>\n",
       "      <td>2024-07-25</td>\n",
       "      <td>2024-08-05</td>\n",
       "      <td>170.04</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TXN015</td>\n",
       "      <td>ACC012</td>\n",
       "      <td>MER015</td>\n",
       "      <td>2024-06-04</td>\n",
       "      <td>2024-08-16</td>\n",
       "      <td>481.38</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   transaction_id account_id merchant_id transaction_date processing_date  \\\n",
       "0          TXN001     ACC012      MER001       2024-07-02      2024-07-20   \n",
       "1          TXN002     ACC004      MER002       2024-09-03      2024-07-12   \n",
       "2          TXN003     ACC014      MER003       2024-08-29      2024-06-11   \n",
       "3          TXN004     ACC014      MER004       2024-08-10      2024-06-09   \n",
       "4          TXN005     ACC006      MER005       2024-06-13      2024-08-16   \n",
       "5          TXN006     ACC010      MER006       2024-08-05      2024-07-29   \n",
       "6          TXN007     ACC014      MER007       2024-06-22      2024-09-02   \n",
       "7          TXN008     ACC006      MER008       2024-07-04      2024-07-21   \n",
       "8          TXN009     ACC005      MER009       2024-08-10      2024-08-25   \n",
       "9          TXN010     ACC015      MER010       2024-07-01      2024-07-13   \n",
       "10         TXN011     ACC010      MER011       2024-07-25      2024-08-20   \n",
       "11         TXN012     ACC005      MER012       2024-06-24      2024-06-30   \n",
       "12         TXN013     ACC003      MER013       2024-06-18      2024-06-18   \n",
       "13         TXN014     ACC005      MER014       2024-07-25      2024-08-05   \n",
       "14         TXN015     ACC012      MER015       2024-06-04      2024-08-16   \n",
       "\n",
       "    amount  processing_time  \n",
       "0   354.28               18  \n",
       "1   499.71              -53  \n",
       "2   168.53              -79  \n",
       "3   132.45              -62  \n",
       "4   374.18               64  \n",
       "5   252.03               -7  \n",
       "6   288.11               72  \n",
       "7   455.89               17  \n",
       "8   375.36               15  \n",
       "9   270.77               12  \n",
       "10  346.12               26  \n",
       "11  465.39                6  \n",
       "12  191.21                0  \n",
       "13  170.04               11  \n",
       "14  481.38               73  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"\"\" select * ,datediff(processing_date,transaction_date) as processing_time\n",
    "from transaction_data\"\"\"\n",
    "pd.read_sql(query,engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2be346-783b-4598-b2e8-c817be1a7850",
   "metadata": {},
   "source": [
    "### 6. Customer Transaction and Profit Analysis (5 Marks):\n",
    "● Task: Calculate the total number of transactions, average transaction value, and total transaction amount for each customer. Order the data frame by Total_Transaction_Amount in descending order and discuss any trends or insights.\n",
    "\n",
    "● Expected Result: Accurate calculations and insightful analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d139354f-0e6d-4c18-afe7-9406cc6c7640",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 127:===============================================>     (180 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+------------------+------------------+\n",
      "|customer_id|no_of_trans|  avg_trans_amount|total_trans_amount|\n",
      "+-----------+-----------+------------------+------------------+\n",
      "|    CUST005|          3|            336.93|           1010.79|\n",
      "|    CUST012|          2|            417.83|            835.66|\n",
      "|    CUST006|          2|415.03499999999997| 830.0699999999999|\n",
      "|    CUST010|          2|           299.075|            598.15|\n",
      "|    CUST014|          3|196.36333333333334|            589.09|\n",
      "|    CUST004|          1|            499.71|            499.71|\n",
      "|    CUST015|          1|            270.77|            270.77|\n",
      "|    CUST003|          1|            191.21|            191.21|\n",
      "|    CUST007|          0|              null|              null|\n",
      "|    CUST011|          0|              null|              null|\n",
      "|    CUST001|          0|              null|              null|\n",
      "|    CUST002|          0|              null|              null|\n",
      "|    CUST009|          0|              null|              null|\n",
      "|    CUST008|          0|              null|              null|\n",
      "|    CUST013|          0|              null|              null|\n",
      "+-----------+-----------+------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "merged_data.createOrReplaceTempView(\"merged_table\")\n",
    "query=\"\"\"SELECT \n",
    "    customer_id,\n",
    "    COUNT(transaction_id) AS no_of_trans,\n",
    "    AVG(amount) AS avg_trans_amount,\n",
    "    SUM(amount) AS total_trans_amount\n",
    "FROM \n",
    "    merged_table\n",
    "GROUP BY \n",
    "    customer_id\n",
    "ORDER BY \n",
    "    total_trans_amount DESC\"\"\"\n",
    "spark.sql(query).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25efa61c-5253-4881-9218-fecdc7b5ea7e",
   "metadata": {},
   "source": [
    "## Bonus Task: Transaction Validation\n",
    "##### Task Description: Implement a transaction validation algorithm to check for invalid transactions. The validation criteria will include:\n",
    "1. Negative Amounts: Ensure that no transaction has a negative amount.\n",
    "\n",
    "2. Future Dates: Ensure that no transaction date is set in the future.\n",
    "\n",
    "3. Required Fields: Check that all required fields (e.g., transaction ID, amount, date) are present.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba372e1d-4b99-4076-b860-1e810b9dce88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 218:==================================>                  (312 + 2) / 475]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------------+----------------+---------------+------+---------+-----------+------------+-------+-------------+-------------+----------------+-----------+--------+---------+-------------+-----------------+-------+\n",
      "|merchant_id|account_id|transaction_id|transaction_date|processing_date|amount|branch_id|customer_id|account_type|balance|customer_name|customer_type|customer_country|branch_name|location|  manager|merchant_name|merchant_category|country|\n",
      "+-----------+----------+--------------+----------------+---------------+------+---------+-----------+------------+-------+-------------+-------------+----------------+-----------+--------+---------+-------------+-----------------+-------+\n",
      "|     MER006|    ACC010|        TXN006|      2024-08-05|     2024-07-29|252.03|   BID003|    CUST010|    Checking|3340.17|  Customer_10|   Individual|          Canada|   Branch_3| Toronto|Manager_3|   Merchant_6|    Entertainment|    USA|\n",
      "|     MER004|    ACC014|        TXN004|      2024-08-10|     2024-06-09|132.45|   BID005|    CUST014|     Savings|3996.16|  Customer_14|   Individual|             USA|   Branch_5|  Berlin|Manager_5|   Merchant_4|         Clothing| Canada|\n",
      "|     MER003|    ACC014|        TXN003|      2024-08-29|     2024-06-11|168.53|   BID005|    CUST014|     Savings|3996.16|  Customer_14|   Individual|             USA|   Branch_5|  Berlin|Manager_5|   Merchant_3|        Groceries| Canada|\n",
      "|     MER002|    ACC004|        TXN002|      2024-09-03|     2024-07-12|499.71|   BID004|    CUST004|     Savings|2518.68|   Customer_4|   Individual|              UK|   Branch_4|New York|Manager_4|   Merchant_2|      Electronics|    USA|\n",
      "|       null|    ACC001|          null|            null|           null|  null|   BID001|    CUST001|    Checking|6028.87|   Customer_1|     Business|              UK|   Branch_1|New York|Manager_1|         null|             null|   null|\n",
      "|       null|    ACC008|          null|            null|           null|  null|   BID005|    CUST008|     Savings| 5803.6|   Customer_8|     Business|             USA|   Branch_5|  Berlin|Manager_5|         null|             null|   null|\n",
      "|       null|    ACC007|          null|            null|           null|  null|   BID001|    CUST007|     Savings|9405.52|   Customer_7|   Individual|              UK|   Branch_1|New York|Manager_1|         null|             null|   null|\n",
      "|       null|    ACC002|          null|            null|           null|  null|   BID004|    CUST002|    Checking|5696.32|   Customer_2|     Business|          Canada|   Branch_4|New York|Manager_4|         null|             null|   null|\n",
      "|       null|    ACC011|          null|            null|           null|  null|   BID002|    CUST011|    Checking|2663.98|  Customer_11|     Business|         Germany|   Branch_2|  Berlin|Manager_2|         null|             null|   null|\n",
      "|       null|    ACC013|          null|            null|           null|  null|   BID003|    CUST013|     Savings| 1203.2|  Customer_13|   Individual|             USA|   Branch_3| Toronto|Manager_3|         null|             null|   null|\n",
      "|       null|    ACC009|          null|            null|           null|  null|   BID005|    CUST009|    Checking| 3842.5|   Customer_9|   Individual|          Canada|   Branch_5|  Berlin|Manager_5|         null|             null|   null|\n",
      "+-----------+----------+--------------+----------------+---------------+------+---------+-----------+------------+-------+-------------+-------------+----------------+-----------+--------+---------+-------------+-----------------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import datediff\n",
    "# copy Original data into temp varial\n",
    "final_data = merged_data\n",
    "\n",
    "# Function to validate transactions\n",
    "def validate_transactions(final_data):\n",
    "    # Query for negative balances\n",
    "    negative_balance = final_data.filter(\"balance < 0\")\n",
    "    \n",
    "    # Query for invalid date differences\n",
    "    future_dates = final_data.filter(datediff(\"processing_date\", \"transaction_date\") < 0)\n",
    "    \n",
    "    # Query for missing transaction details\n",
    "    check_required_fields = final_data.filter(col('transaction_id').isNull()) \\\n",
    "                                       .filter(col('amount').isNull()) \\\n",
    "                                       .filter(col('transaction_date').isNull())\n",
    "    \n",
    "    # Combine all above queries\n",
    "    return negative_balance.union(future_dates).union(check_required_fields)\n",
    "\n",
    "# Display the results\n",
    "validate_transactions(final_data).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dad455-a05d-46b9-8d34-17bde90408bc",
   "metadata": {},
   "source": [
    "### Problem Statement: Counting Prime Numbers with Kafka (10 Marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d82958aa-457f-4991-85bb-4b92a4ee9353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: kafka-python in /home/maneelcha49dgre/.local/lib/python3.9/site-packages (2.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install kafka-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4ebd7385-5c68-4e8a-9e61-b842ad2c1b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer\n",
    "import csv\n",
    "import json\n",
    "#starting a topic with kafka producer\n",
    "def kafka_producer():\n",
    "    #initialize the producer\n",
    "    producer=KafkaProducer(\n",
    "        bootstrap_servers=['master:9092'],\n",
    "        value_serializer=lambda x:json.dumps(x).encode('utf-8')\n",
    "    )\n",
    "    i=1\n",
    "    while(i<101):\n",
    "        topic_name=\"num_topics\"\n",
    "        message=int(i)\n",
    "        producer.send(topic_name,message)\n",
    "        i+=1\n",
    "    producer.flush()\n",
    "    producer.close()\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    kafka_producer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5070f7a9-4a84-4acd-9780-7d1b3bbfc9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of prime numbers from 1 to 100 : 25\n"
     ]
    }
   ],
   "source": [
    "from kafka import KafkaConsumer\n",
    "import json\n",
    "from collections import Counter\n",
    "from math import sqrt\n",
    "\n",
    "def check_prime(num):\n",
    "    global number\n",
    "    if(num<2):\n",
    "        return False\n",
    "    if(num==2):\n",
    "        return True\n",
    "    for i in range(2,int(sqrt(num)+1)):\n",
    "        if(num%i==0):\n",
    "            return False\n",
    "    return True;\n",
    "        \n",
    "\n",
    "def kafka_consumer_example(lm):\n",
    "    consumer = KafkaConsumer(\n",
    "        'num_topics',\n",
    "        bootstrap_servers = ['master:9092'],\n",
    "        auto_offset_reset = 'earliest',\n",
    "        enable_auto_commit = True,\n",
    "        value_deserializer=lambda x: int(x.decode('utf-8'))\n",
    "    )\n",
    "    count=0\n",
    "    total=0\n",
    "    for num in consumer:\n",
    "        val=num.value\n",
    "        if(check_prime(val)):\n",
    "            count+=1\n",
    "        total+=1\n",
    "        if(total>=lm):\n",
    "            break\n",
    "    print(\"Total Number of prime numbers from 1 to 100 :\",count)\n",
    "    consumer.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    kafka_consumer_example(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
